image: node #globally download our docker image so that we dont need to download it everytime

#below are the order of the stages in our pipeline
#some stages run 1 by 1 some run at the same time
stages:
  - build
  - test
  - system review
  - deploy staging
  - test staging deployment
  - deploy production
  - test production deployment

#Global cache configuration
cache:
  key: ${CI_COMMIT_REF_SLUG} #this is a predefined variable to point at your current branch
  paths:
    - node_modules/

variables:
  STAGING_DOMAIN: medical-tin-staging.surge.sh
  PRODUCTION_DOMAIN: medical-tin-prodction.surge.sh

build website:
  stage: build
  only:
    - master
    - merge_requests
  script:
    - echo $CI_COMMIT_SHORT_SHA
    - npm install
    - npm install -g gatsby-cli
    - gatsby build
    - sed -i "s/%%VERSION%%/$CI_COMMIT_SHORT_SHA/" ./public/index.html
  artifacts:
    paths:
      - ./public

test artifact:
  image: alpine #what does this image do?
  stage: test
  only:
    - master
    - merge_requests
  script:
    - test -f ./public/index.html
    - grep -q "gatsby" ./public/index.html

test website:
  stage: test
  only:
    - master
    - merge_requests
  script:
    - npm install
    - npm install -g gatsby-cli
    - gatsby serve & #start the server using the production build port 9000
    - sleep 3 #add a command so that the server has some time to spin up before next command
    - curl "http://localhost:9000" | tac | tac | grep -q "Gatsby" #download the contents of this website from the input and pass it into the grep
    #what tac is doing is making the grep wait until all the output is written from the curl

system review:
  stage: system review
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url: "http://medical-tin-$CI_ENVIRONMENT_SLUG.surge.sh"
    on_stop: teardown system review
  only:
    - merge_requests
  script:
    - echo "deploy system review"
    - npm install --global surge
    - surge --project ./public --domain medical-tin-$CI_ENVIRONMENT_SLUG.surge.sh

teardown system review:
  only: 
    - merge_requests
  stage: system review
  variables:
    GIT_STRATEGY: none #makes sure the job doesnt try to clone the branch as it may be deleted
  script:
    - echo "teardown system review"
    - npm install --global surge
    - surge teardown medical-tin-$CI_ENVIRONMENT_SLUG.surge.sh
  when: manual #manual works in a different way here. When we manually merge it will run this job
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop

deploy staging:
  stage: deploy staging
  environment:
    name: staging
    url: "http://$STAGING_DOMAIN"
  only:
    - master
  script:
    - echo "deploy staging"
    - npm install --global surge
    - surge --project ./public --domain $STAGING_DOMAIN
    
test staging deployment:
  stage: test staging deployment
  image: alpine
  cache: {}
  only:
    - master
  script:
    - echo "test staging deployment"
    - apk add --no-cache curl
    - curl "$STAGING_DOMAIN" | tac | tac | grep "Gatsby"

deploy production:
  stage: deploy production
  environment:
    name: production
    url: "http://$PRODUCTION_DOMAIN"
  only:
    - master
  script:
    - npm install --global surge
    - surge --project ./public --domain $PRODUCTION_DOMAIN

test production deployment:
  image: alpine
  stage: test production deployment
  cache: {}
  only:
    - master
  script:
    - apk add --no-cache curl
    - curl "$PRODUCTION_DOMAIN" | tac | tac | grep "Gatsby"
    - curl "$PRODUCTION_DOMAIN" | tac | tac | grep "$CI_COMMIT_SHORT_SHA"


